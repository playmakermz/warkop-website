{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Menjalankan LLM dengan Colab\n",
        "\n",
        "Percobaan disini bisa digunakan juga dengan model LLM lainnya, selain deepseek.  \n",
        "\n",
        "Minimal penggunaan GPU adalah T4 GPU, ini saja sudah mepet. GPU Usage 13/15 GB.\n",
        "\n",
        "Ref:\n",
        "\n",
        "https://www.google.com/url?q=https%3A%2F%2Fmedium.com%2F%40hakimnaufal%2Ftrying-out-vllm-deepseek-r1-in-google-colab-a-quick-guide-a4fe682b8665\n"
      ],
      "metadata": {
        "id": "f3d_TeN2xWVh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Install PIP yang dibutuhkan\n"
      ],
      "metadata": {
        "id": "FKGGKxz-x3PD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T4Npr9W4vwyB",
        "outputId": "4e1ad3e5-464c-4dfa-cbdc-595c5dcc3dc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (0.116.2)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.4.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (0.35.0)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.48.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from fastapi) (2.11.9)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (4.15.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (8.2.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.49.0,>=0.40.0->fastapi) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Downloading pyngrok-7.4.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.4.0\n",
            "Collecting vllm\n",
            "  Downloading vllm-0.10.2-cp38-abi3-manylinux1_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from vllm) (2024.11.6)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from vllm) (5.5.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from vllm) (5.9.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from vllm) (0.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from vllm) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from vllm) (4.67.1)\n",
            "Collecting blake3 (from vllm)\n",
            "  Downloading blake3-1.0.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (217 bytes)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from vllm) (9.0.0)\n",
            "Requirement already satisfied: transformers>=4.55.2 in /usr/local/lib/python3.12/dist-packages (from vllm) (4.56.1)\n",
            "Requirement already satisfied: tokenizers>=0.21.1 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.22.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from vllm) (5.29.5)\n",
            "Requirement already satisfied: fastapi>=0.115.0 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.116.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from vllm) (3.12.15)\n",
            "Requirement already satisfied: openai>=1.99.1 in /usr/local/lib/python3.12/dist-packages (from vllm) (1.108.0)\n",
            "Requirement already satisfied: pydantic>=2.11.7 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.11.9)\n",
            "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.22.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from vllm) (11.3.0)\n",
            "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm)\n",
            "  Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.11.0)\n",
            "Collecting lm-format-enforcer==0.11.3 (from vllm)\n",
            "  Downloading lm_format_enforcer-0.11.3-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting llguidance<0.8.0,>=0.7.11 (from vllm)\n",
            "  Downloading llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting outlines_core==0.2.11 (from vllm)\n",
            "  Downloading outlines_core-0.2.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
            "Collecting diskcache==5.6.3 (from vllm)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: lark==1.2.2 in /usr/local/lib/python3.12/dist-packages (from vllm) (1.2.2)\n",
            "Collecting xgrammar==0.1.23 (from vllm)\n",
            "  Downloading xgrammar-0.1.23-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.12/dist-packages (from vllm) (4.15.0)\n",
            "Requirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.12/dist-packages (from vllm) (3.19.1)\n",
            "Collecting partial-json-parser (from vllm)\n",
            "  Downloading partial_json_parser-0.2.1.1.post6-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: pyzmq>=25.0.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (26.2.1)\n",
            "Collecting msgspec (from vllm)\n",
            "  Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting gguf>=0.13.0 (from vllm)\n",
            "  Downloading gguf-0.17.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting mistral_common>=1.8.2 (from mistral_common[audio,image]>=1.8.2->vllm)\n",
            "  Downloading mistral_common-1.8.5-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: opencv-python-headless>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (4.12.0.88)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from vllm) (6.0.2)\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (1.17.0)\n",
            "Collecting setuptools<80,>=77.0.3 (from vllm)\n",
            "  Downloading setuptools-79.0.1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from vllm) (0.8.1)\n",
            "Collecting compressed-tensors==0.11.0 (from vllm)\n",
            "  Downloading compressed_tensors-0.11.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting depyf==0.19.0 (from vllm)\n",
            "  Downloading depyf-0.19.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from vllm) (3.1.1)\n",
            "Collecting watchfiles (from vllm)\n",
            "  Downloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: python-json-logger in /usr/local/lib/python3.12/dist-packages (from vllm) (3.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from vllm) (1.16.2)\n",
            "Collecting ninja (from vllm)\n",
            "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting pybase64 (from vllm)\n",
            "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Collecting cbor2 (from vllm)\n",
            "  Downloading cbor2-5.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting setproctitle (from vllm)\n",
            "  Downloading setproctitle-1.3.7-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (10 kB)\n",
            "Collecting openai-harmony>=0.0.3 (from vllm)\n",
            "  Downloading openai_harmony-0.0.4-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
            "Collecting numba==0.61.2 (from vllm)\n",
            "  Downloading numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting ray>=2.48.0 (from ray[cgraph]>=2.48.0->vllm)\n",
            "  Downloading ray-2.49.2-cp312-cp312-manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: torch==2.8.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchaudio==2.8.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision==0.23.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.23.0+cu126)\n",
            "Collecting xformers==0.0.32.post1 (from vllm)\n",
            "  Downloading xformers-0.0.32.post1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.12/dist-packages (from compressed-tensors==0.11.0->vllm) (2.4.6)\n",
            "Collecting astor (from depyf==0.19.0->vllm)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from depyf==0.19.0->vllm) (0.3.8)\n",
            "Collecting interegular>=0.3.2 (from lm-format-enforcer==0.11.3->vllm)\n",
            "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from lm-format-enforcer==0.11.3->vllm) (25.0)\n",
            "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba==0.61.2->vllm)\n",
            "  Downloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm) (3.4.0)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (0.48.0)\n",
            "Collecting fastapi-cli>=0.0.8 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading fastapi_cli-0.0.13-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.28.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.0.20)\n",
            "Collecting email-validator>=2.0.0 (from fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading email_validator-2.3.0-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: uvicorn>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.35.0)\n",
            "Requirement already satisfied: jsonschema>=4.21.1 in /usr/local/lib/python3.12/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (4.25.1)\n",
            "Collecting pydantic-extra-types>=2.10.5 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm)\n",
            "  Downloading pydantic_extra_types-2.10.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.1->vllm) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.1->vllm) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.1->vllm) (0.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.1->vllm) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.7->vllm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.7->vllm) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.7->vllm) (0.4.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from ray>=2.48.0->ray[cgraph]>=2.48.0->vllm) (8.2.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray>=2.48.0->ray[cgraph]>=2.48.0->vllm) (1.1.1)\n",
            "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.12/dist-packages (from ray[cgraph]>=2.48.0->vllm) (13.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (2025.8.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.21.1->vllm) (0.35.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.55.2->vllm) (0.6.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (1.20.1)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typer>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.17.4)\n",
            "Collecting rich-toolkit>=0.14.8 (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading rich_toolkit-0.15.1-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting fastapi-cloud-cli>=0.1.1 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading fastapi_cloud_cli-0.3.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.21.1->vllm) (1.1.10)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.8.0->vllm) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.27.1)\n",
            "Collecting pycountry>=23 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm)\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.8.0->vllm) (1.3.0)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.1.1)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (15.0.1)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.12/dist-packages (from cupy-cuda12x->ray[cgraph]>=2.48.0->vllm) (0.8.3)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.13.1)\n",
            "Requirement already satisfied: soxr>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (1.0.0)\n",
            "Collecting rignore>=0.5.1 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading rignore-0.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: sentry-sdk>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.38.0)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.12/dist-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (13.9.4)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2.0.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.15.1->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.5.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2.23)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.2)\n",
            "Downloading vllm-0.10.2-cp38-abi3-manylinux1_x86_64.whl (436.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.4/436.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading compressed_tensors-0.11.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.0/180.0 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading depyf-0.19.0-py3-none-any.whl (39 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lm_format_enforcer-0.11.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m130.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outlines_core-0.2.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.32.post1-cp39-abi3-manylinux_2_28_x86_64.whl (117.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xgrammar-0.1.23-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gguf-0.17.1-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mistral_common-1.8.5-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai_harmony-0.0.4-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\n",
            "Downloading ray-2.49.2-cp312-cp312-manylinux2014_x86_64.whl (70.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-79.0.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blake3-1.0.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (387 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m387.9/387.9 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cbor2-5.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.9/284.9 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.6/213.6 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading partial_json_parser-0.2.1.1.post6-py3-none-any.whl (10 kB)\n",
            "Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.7-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (32 kB)\n",
            "Downloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading email_validator-2.3.0-py3-none-any.whl (35 kB)\n",
            "Downloading fastapi_cli-0.0.13-py3-none-any.whl (11 kB)\n",
            "Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
            "Downloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_extra_types-2.10.5-py3-none-any.whl (38 kB)\n",
            "Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi_cloud_cli-0.3.0-py3-none-any.whl (19 kB)\n",
            "Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (510 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m142.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich_toolkit-0.15.1-py3-none-any.whl (29 kB)\n",
            "Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m120.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rignore-0.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (951 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m951.1/951.1 kB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvloop, setuptools, setproctitle, rignore, pycountry, pybase64, partial-json-parser, outlines_core, ninja, msgspec, llvmlite, llguidance, interegular, httptools, gguf, dnspython, diskcache, cbor2, blake3, astor, watchfiles, numba, email-validator, depyf, rich-toolkit, pydantic-extra-types, prometheus-fastapi-instrumentator, openai-harmony, lm-format-enforcer, xformers, ray, fastapi-cloud-cli, fastapi-cli, xgrammar, mistral_common, compressed-tensors, vllm\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.43.0\n",
            "    Uninstalling llvmlite-0.43.0:\n",
            "      Successfully uninstalled llvmlite-0.43.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.60.0\n",
            "    Uninstalling numba-0.60.0:\n",
            "      Successfully uninstalled numba-0.60.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed astor-0.8.1 blake3-1.0.7 cbor2-5.7.0 compressed-tensors-0.11.0 depyf-0.19.0 diskcache-5.6.3 dnspython-2.8.0 email-validator-2.3.0 fastapi-cli-0.0.13 fastapi-cloud-cli-0.3.0 gguf-0.17.1 httptools-0.6.4 interegular-0.3.3 llguidance-0.7.30 llvmlite-0.44.0 lm-format-enforcer-0.11.3 mistral_common-1.8.5 msgspec-0.19.0 ninja-1.13.0 numba-0.61.2 openai-harmony-0.0.4 outlines_core-0.2.11 partial-json-parser-0.2.1.1.post6 prometheus-fastapi-instrumentator-7.1.0 pybase64-1.4.2 pycountry-24.6.1 pydantic-extra-types-2.10.5 ray-2.49.2 rich-toolkit-0.15.1 rignore-0.7.0 setproctitle-1.3.7 setuptools-79.0.1 uvloop-0.21.0 vllm-0.10.2 watchfiles-1.1.0 xformers-0.0.32.post1 xgrammar-0.1.23\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack"
                ]
              },
              "id": "2119b4f4006c44b680c03c3fe048a31f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastai in /usr/local/lib/python3.12/dist-packages (2.8.4)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (from fastai) (24.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from fastai) (25.0)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.12/dist-packages (from fastai) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.9,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from fastai) (1.8.8)\n",
            "Requirement already satisfied: fasttransform>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastai) (0.0.2)\n",
            "Requirement already satisfied: torchvision>=0.11 in /usr/local/lib/python3.12/dist-packages (from fastai) (0.23.0+cu126)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from fastai) (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from fastai) (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from fastai) (2.32.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from fastai) (6.0.2)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.12/dist-packages (from fastai) (1.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from fastai) (11.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from fastai) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from fastai) (1.16.2)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.12/dist-packages (from fastai) (3.8.7)\n",
            "Requirement already satisfied: plum-dispatch in /usr/local/lib/python3.12/dist-packages (from fastai) (2.5.7)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from fastai) (3.1.1)\n",
            "Requirement already satisfied: torch<2.9,>=1.10 in /usr/local/lib/python3.12/dist-packages (from fastai) (2.8.0+cu126)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy<4->fastai) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy<4->fastai) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy<4->fastai) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy<4->fastai) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy<4->fastai) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy<4->fastai) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy<4->fastai) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy<4->fastai) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy<4->fastai) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy<4->fastai) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy<4->fastai) (0.17.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy<4->fastai) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy<4->fastai) (2.0.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy<4->fastai) (2.11.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy<4->fastai) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy<4->fastai) (79.0.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy<4->fastai) (3.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->fastai) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->fastai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->fastai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->fastai) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=1.10->fastai) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=1.10->fastai) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=1.10->fastai) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=1.10->fastai) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=1.10->fastai) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=1.10->fastai) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=1.10->fastai) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=1.10->fastai) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=1.10->fastai) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=1.10->fastai) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=1.10->fastai) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=1.10->fastai) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=1.10->fastai) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=1.10->fastai) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=1.10->fastai) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=1.10->fastai) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=1.10->fastai) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=1.10->fastai) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=1.10->fastai) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=1.10->fastai) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->fastai) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->fastai) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->fastai) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->fastai) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->fastai) (3.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->fastai) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->fastai) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->fastai) (2025.2)\n",
            "Requirement already satisfied: beartype>=0.16.2 in /usr/local/lib/python3.12/dist-packages (from plum-dispatch->fastai) (0.21.0)\n",
            "Requirement already satisfied: rich>=10.0 in /usr/local/lib/python3.12/dist-packages (from plum-dispatch->fastai) (13.9.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->fastai) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->fastai) (3.6.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->fastai) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.0->plum-dispatch->fastai) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.0->plum-dispatch->fastai) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<2.9,>=1.10->fastai) (1.3.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<4->fastai) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<4->fastai) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai) (1.5.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai) (0.22.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai) (7.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy<4->fastai) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.0->plum-dispatch->fastai) (0.1.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4->fastai) (1.17.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install fastapi nest-asyncio pyngrok uvicorn\n",
        "!pip install vllm # you could pass if you don't want to be prompted to restart runtime !pip install --quiet vllm\n",
        "!pip install fastai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Penggunaan PIP:\n",
        "\n",
        "- FastApi: adalah python web framework untuk membuat API. Dimana disini user bisa mengirimkan data dan mendapatkan respon dari model\n",
        "\n",
        "- uvicorn: adalah ASGI ( Asynchronous Server Gateway Interface ) server. Uvicor akan melengkapi aplikasi web yang dibuat olef FastApi dan menjalankannya. Secara sederhana, FastApi adalah protokol dan Uvicorn adalah yang menjalankan protokol.\n",
        "\n",
        "- nest-asyncio: Ini adalah alat untuk membantu kita untuk menjalankan dua proses secara sekaligus. Ini nanti akan kita pakai untuk menjalankan loop dari FastAPI ataupun Uvicorn. karena mereka berdua sama-sama memiliki loop dan saling ketergantungan.\n",
        "\n",
        "- pyngrok: Ini adalah wrapper untuk ngrok. Ngrok adalah alat yang dapat membantu kita untuk mengirimkan data ke luar dari komputer, seperti di dunia internet. ini sangat membantu untuk pengembangan, jadi kita tidak perlu repot-repot menghosting aplikasi, aplikasi lokal kita sudah bisa ada di internet.\n",
        "\n",
        "- vllm: Ini adalah library python penting untuk menjalankan LLM. Keuntungan adalah meningkatkan kecepatan dan efektifitas, mendorong untuk menerima request yang lebih banyak per detik dan meningkatkan kemampuan memory dari model.\n",
        "\n",
        "- fastai: adalah library yang dibangun diatas PyTorch. ini akan menyederhakan proses training dan deploying neuiral network. Jika tadi vllm ada untuk meningkatkan penggunaan LLM inference, fastai akan menyediakan alat-alat yang kita butuhkan untuk melakukan training.\n",
        "\n",
        "\n",
        "**Tetapi** disini kita tidak akan menggunakan ngrok dan uvicorn terlebih dahulu\n",
        "\n"
      ],
      "metadata": {
        "id": "3LztUqueyQv1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kamu bisa coba-coba model lain disini: https://www.google.com/url?q=https%3A%2F%2Fhuggingface.co%2Fdeepseek-ai%2FDeepSeek-R1%233-model-downloads\n",
        "\n"
      ],
      "metadata": {
        "id": "UpNDSYrm3JZ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Menjalankan model di background"
      ],
      "metadata": {
        "id": "VqL_qMmV30qb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Untuk menjalankan model\n",
        "import subprocess\n",
        "# model bisa diambil dari sini: https://huggingface.co/deepseek-ai/DeepSeek-R1#3-model-downloads\n",
        "model = 'deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B'\n",
        "\n",
        "# Mulai Jalankan vllm dibagian background komputer\n",
        "vllm_process = subprocess.Popen([\n",
        "    'vllm',\n",
        "    'serve',\n",
        "    model,\n",
        "    '--trust-remote-code',\n",
        "    '--dtype', 'half',\n",
        "    '--max-model-len', '16384',\n",
        "    '--tensor-parallel-size', '1' # Subcommand akan mendeskripsikan penggunaan model\n",
        "], stdout=subprocess.PIPE, stderr=subprocess.PIPE, start_new_session=True)"
      ],
      "metadata": {
        "id": "Do11cKri3Ds0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Check dan Test vllm\n",
        "\n",
        "Prossses ini akan menjadi test pertama. kita akan mengetahui apakah vllm berjalan dengan baik jika sudah dijalankan."
      ],
      "metadata": {
        "id": "bQCjhMoT4cQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "from typing import Tuple\n",
        "import sys\n",
        "\n",
        "def check_vllm_status(url: str = \"http://localhost:8000/health\") -> bool:\n",
        "    \"\"\"Untuk mencari tau apakajh LLM berfungsi normal.\"\"\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        return response.status_code == 200\n",
        "    except requests.exceptions.ConnectionError:\n",
        "        return False\n",
        "\n",
        "def monitor_vllm_process(vllm_process: subprocess.Popen, check_interval: int = 5) -> Tuple[bool, str, str]:\n",
        "    \"\"\"\n",
        "    Monitoring status vllm dan prosesnya , stdout, and stderr.\n",
        "    Returns: (success, stdout, stderr)\n",
        "    \"\"\"\n",
        "    print(\"Starting VLLM server monitoring...\")\n",
        "\n",
        "    while vllm_process.poll() is None:  # While loop selama proses masih berjalan\n",
        "        if check_vllm_status():\n",
        "            print(\"✓ VLLM server is up and running!\")\n",
        "            return True, \"\", \"\"\n",
        "\n",
        "        print(\"Waiting for VLLM server to start...\")\n",
        "        time.sleep(check_interval)\n",
        "\n",
        "        # Menampilkan Output jika ditemukan.\n",
        "        if vllm_process.stdout.readable():\n",
        "            stdout = vllm_process.stdout.read1().decode('utf-8')\n",
        "            if stdout:\n",
        "                print(\"STDOUT:\", stdout)\n",
        "\n",
        "        if vllm_process.stderr.readable():\n",
        "            stderr = vllm_process.stderr.read1().decode('utf-8')\n",
        "            if stderr:\n",
        "                print(\"STDERR:\", stderr)\n",
        "\n",
        "    # Jika sampai disini, maka proses telah selesai\n",
        "    stdout, stderr = vllm_process.communicate()\n",
        "    return False, stdout.decode('utf-8'), stderr.decode('utf-8')"
      ],
      "metadata": {
        "id": "xnl4gCAc40jK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Buat persimpangan jika VLLM sukses dan tidak"
      ],
      "metadata": {
        "id": "6DGQ2piv75qq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    success, stdout, stderr = monitor_vllm_process(vllm_process)\n",
        "\n",
        "    if not success:\n",
        "        print(\"\\n❌ VLLM server failed to start!\")\n",
        "        print(\"\\nFull STDOUT:\", stdout)\n",
        "        print(\"\\nFull STDERR:\", stderr)\n",
        "        sys.exit(1)\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\n⚠️ Monitoring interrupted by user\")\n",
        "    # # This should just exited the process of probing, not the vllm, if you want it then you coul uncomment this.\n",
        "    # vllm_process.terminate()\n",
        "    # try:\n",
        "    #     vllm_process.wait(timeout=5)\n",
        "    # except subprocess.TimeoutExpired:\n",
        "    #     vllm_process.kill()\n",
        "\n",
        "    stdout, stderr = vllm_process.communicate()\n",
        "    if stdout: print(\"\\nFinal STDOUT:\", stdout.decode('utf-8'))\n",
        "    if stderr: print(\"\\nFinal STDERR:\", stderr.decode('utf-8'))\n",
        "    sys.exit(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9kEm01M72lr",
        "outputId": "44bae371-82dd-4ec2-b8f0-d0dccd91af54"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting VLLM server monitoring...\n",
            "Waiting for VLLM server to start...\n",
            "STDOUT: INFO 10-03 07:53:01 [__init__.py:216] Automatically detected platform cuda.\n",
            "\n",
            "STDERR: 2025-10-03 07:52:54.589819: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1759477974.610806     804 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1759477974.616665     804 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1759477974.632021     804 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759477974.632041     804 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759477974.632043     804 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759477974.632044     804 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-03 07:52:54.637758: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "Waiting for VLLM server to start...\n",
            "STDOUT: \u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO 10-03 07:53:07 [api_server.py:1896] vLLM API server version 0.10.2\n",
            "\n",
            "STDERR: \u001b[1;36m(APIServer pid=804)\u001b[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
            "\n",
            "Waiting for VLLM server to start...\n",
            "STDOUT: \u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO 10-03 07:53:07 [utils.py:328] non-default args: {'model_tag': 'deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', 'model': 'deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', 'trust_remote_code': True, 'dtype': 'half', 'max_model_len': 16384}\n",
            "\n",
            "STDERR: \u001b[1;36m(APIServer pid=804)\u001b[0;0m `torch_dtype` is deprecated! Use `dtype` instead!\n",
            "\n",
            "Waiting for VLLM server to start...\n",
            "STDOUT: \u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO 10-03 07:53:24 [__init__.py:742] Resolved architecture: Qwen2ForCausalLM\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m WARNING 10-03 07:53:24 [__init__.py:2767] Casting torch.bfloat16 to torch.float16.\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO 10-03 07:53:24 [__init__.py:1815] Using max model len 16384\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO 10-03 07:53:26 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=2048.\n",
            "\n",
            "STDERR: 2025-10-03 07:53:32.958987: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\n",
            "Waiting for VLLM server to start...\n",
            "STDOUT: INFO 10-03 07:53:38 [__init__.py:216] Automatically detected platform cuda.\n",
            "\n",
            "STDERR: WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1759478012.979129    1023 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1759478012.984959    1023 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1759478012.999404    1023 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759478012.999421    1023 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759478012.999423    1023 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759478012.999425    1023 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\n",
            "Waiting for VLLM server to start...\n",
            "STDOUT: \u001b[1;36m(EngineCore_DP0 pid=1023)\u001b[0;0m INFO 10-03 07:53:40 [core.py:654] Waiting for init message from front-end.\n",
            "\u001b[1;36m(EngineCore_DP0 pid=1023)\u001b[0;0m INFO 10-03 07:53:40 [core.py:76] Initializing a V1 LLM engine (v0.10.2) with config: model='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', speculative_config=None, tokenizer='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=16384, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\",\"vllm.mamba_mixer2\",\"vllm.mamba_mixer\",\"vllm.short_conv\",\"vllm.linear_attention\",\"vllm.plamo2_mamba_mixer\",\"vllm.gdn_attention\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":1,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"pass_config\":{},\"max_capture_size\":512,\"local_cache_dir\":null}\n",
            "\u001b[1;36m(EngineCore_DP0 pid=1023)\u001b[0;0m ERROR 10-03 07:53:40 [fa_utils.py:57] Cannot use FA version 2 is not supported due to FA2 is only supported on devices with compute capability >= 8\n",
            "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
            "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
            "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
            "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
            "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
            "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
            "\u001b[1;36m(EngineCore_DP0 pid=1023)\u001b[0;0m INFO 10-03 07:53:42 [parallel_state.py:1165] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
            "\u001b[1;36m(EngineCore_DP0 pid=1023)\u001b[0;0m WARNING 10-03 07:53:42 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
            "\u001b[1;36m(EngineCore_DP0 pid=1023)\u001b[0;0m INFO 10-03 07:53:42 [gpu_model_runner.py:2338] Starting to load model deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B...\n",
            "\u001b[1;36m(EngineCore_DP0 pid=1023)\u001b[0;0m INFO 10-03 07:53:42 [gpu_model_runner.py:2370] Loading model from scratch...\n",
            "\n",
            "STDERR: [W1003 07:53:42.453468465 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())\n",
            "\n",
            "Waiting for VLLM server to start...\n",
            "STDOUT: \u001b[1;36m(EngineCore_DP0 pid=1023)\u001b[0;0m INFO 10-03 07:53:43 [cuda.py:368] Using FlexAttention backend on V1 engine.\n",
            "\u001b[1;36m(EngineCore_DP0 pid=1023)\u001b[0;0m INFO 10-03 07:53:43 [weight_utils.py:348] Using model weights format ['*.safetensors']\n",
            "\n",
            "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
            "\n",
            "Waiting for VLLM server to start...\n",
            "STDOUT: \u001b[1;36m(EngineCore_DP0 pid=1023)\u001b[0;0m INFO 10-03 07:54:58 [weight_utils.py:369] Time spent downloading weights for deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B: 74.877159 seconds\n",
            "\u001b[1;36m(EngineCore_DP0 pid=1023)\u001b[0;0m INFO 10-03 07:54:58 [weight_utils.py:406] No model.safetensors.index.json found in remote.\n",
            "\n",
            "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:11<00:00, 11.95s/it]\n",
            "\n",
            "Waiting for VLLM server to start...\n",
            "STDOUT: \u001b[1;36m(EngineCore_DP0 pid=1023)\u001b[0;0m INFO 10-03 07:55:10 [default_loader.py:268] Loading weights took 12.05 seconds\n",
            "\u001b[1;36m(EngineCore_DP0 pid=1023)\u001b[0;0m INFO 10-03 07:55:11 [gpu_model_runner.py:2392] Model loading took 3.3466 GiB and 87.731081 seconds\n",
            "\n",
            "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:11<00:00, 11.95s/it]\n",
            "\u001b[1;36m(EngineCore_DP0 pid=1023)\u001b[0;0m \n",
            "\n",
            "Waiting for VLLM server to start...\n",
            "STDOUT: \u001b[1;36m(EngineCore_DP0 pid=1023)\u001b[0;0m INFO 10-03 07:55:19 [backends.py:539] Using cache directory: /root/.cache/vllm/torch_compile_cache/96148c857f/rank_0_0/backbone for vLLM's torch.compile\n",
            "\u001b[1;36m(EngineCore_DP0 pid=1023)\u001b[0;0m INFO 10-03 07:55:19 [backends.py:550] Dynamo bytecode transform time: 7.93 s\n",
            "\n",
            "STDERR: \u001b[1;36m(EngineCore_DP0 pid=1023)\u001b[0;0m [rank0]:W1003 07:55:24.297000 1023 torch/_inductor/utils.py:1436] [0/0] Not enough SMs to use max_autotune_gemm mode\n",
            "\n",
            "Waiting for VLLM server to start...\n",
            "STDOUT: \u001b[1;36m(EngineCore_DP0 pid=1023)\u001b[0;0m INFO 10-03 07:55:23 [backends.py:194] Cache the graph for dynamic shape for later use\n",
            "\n",
            "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/67 [00:00<?, ?it/s]\n",
            "Waiting for VLLM server to start...\n",
            "STDOUT: \u001b[1;36m(EngineCore_DP0 pid=1023)\u001b[0;0m INFO 10-03 07:55:45 [backends.py:215] Compiling a graph for dynamic shape takes 25.00 s\n",
            "\u001b[1;36m(EngineCore_DP0 pid=1023)\u001b[0;0m INFO 10-03 07:55:46 [monitor.py:34] torch.compile takes 32.94 s in total\n",
            "\u001b[1;36m(EngineCore_DP0 pid=1023)\u001b[0;0m INFO 10-03 07:55:48 [gpu_worker.py:298] Available KV cache memory: 8.52 GiB\n",
            "\u001b[1;36m(EngineCore_DP0 pid=1023)\u001b[0;0m INFO 10-03 07:55:48 [kv_cache_utils.py:864] GPU KV cache size: 318,912 tokens\n",
            "\u001b[1;36m(EngineCore_DP0 pid=1023)\u001b[0;0m INFO 10-03 07:55:48 [kv_cache_utils.py:868] Maximum concurrency for 16,384 tokens per request: 19.46x\n",
            "\n",
            "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 67/67 [00:04<00:00, 14.28it/s]\n",
            "\n",
            "Waiting for VLLM server to start...\n",
            "STDOUT: \u001b[1;36m(EngineCore_DP0 pid=1023)\u001b[0;0m INFO 10-03 07:55:54 [gpu_model_runner.py:3118] Graph capturing finished in 6 secs, took 0.45 GiB\n",
            "\u001b[1;36m(EngineCore_DP0 pid=1023)\u001b[0;0m INFO 10-03 07:55:54 [gpu_worker.py:391] Free memory on device (14.63/14.74 GiB) on startup. Desired GPU memory utilization is (0.9, 13.27 GiB). Actual usage is 3.35 GiB for weight, 1.39 GiB for peak activation, 0.01 GiB for non-torch memory, and 0.45 GiB for CUDAGraph memory. Replace gpu_memory_utilization config with `--kv-cache-memory=8504594022` to fit into requested memory, or `--kv-cache-memory=9962711040` to fully utilize gpu memory. Current kv cache memory in use is 9144225382 bytes.\n",
            "\u001b[1;36m(EngineCore_DP0 pid=1023)\u001b[0;0m INFO 10-03 07:55:54 [core.py:218] init engine (profile, create kv cache, warmup model) took 43.20 seconds\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO 10-03 07:55:55 [loggers.py:142] Engine 000: vllm cache_config_info with initialization after num_gpu_blocks is: 19932\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO 10-03 07:55:55 [async_llm.py:180] Torch profiler disabled. AsyncLLM CPU traces will not be collected.\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO 10-03 07:55:56 [api_server.py:1692] Supported_tasks: ['generate']\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m WARNING 10-03 07:55:56 [__init__.py:1695] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO 10-03 07:55:56 [serving_responses.py:130] Using default chat sampling params from model: {'temperature': 0.6, 'top_p': 0.95}\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO 10-03 07:55:56 [serving_chat.py:137] Using default chat sampling params from model: {'temperature': 0.6, 'top_p': 0.95}\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO 10-03 07:55:56 [serving_completion.py:76] Using default completion sampling params from model: {'temperature': 0.6, 'top_p': 0.95}\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO 10-03 07:55:56 [api_server.py:1971] Starting vLLM API server 0 on http://0.0.0.0:8000\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO 10-03 07:55:56 [launcher.py:36] Available routes are:\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO 10-03 07:55:56 [launcher.py:44] Route: /openapi.json, Methods: HEAD, GET\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO 10-03 07:55:56 [launcher.py:44] Route: /docs, Methods: HEAD, GET\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO 10-03 07:55:56 [launcher.py:44] Route: /docs/oauth2-redirect, Methods: HEAD, GET\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO 10-03 07:55:56 [launcher.py:44] Route: /redoc, Methods: HEAD, GET\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO 10-03 07:55:56 [launcher.py:44] Route: /health, Methods: GET\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO 10-03 07:55:56 [launcher.py:44] Route: /load, Methods: GET\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO 10-03 07:55:56 [launcher.py:44] Route: /ping, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO 10-03 07:55:56 [launcher.py:44] Route: /ping, Methods: GET\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO 10-03 07:55:56 [launcher.py:44] Route: /tokenize, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO 10-03 07:55:56 [launcher.py:44] Route: /detokenize, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO 10-03 07:55:56 [launcher.py:44] Route: /v1/models, Methods: GET\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO 10-03 07:55:56 [launcher.py:44] Route: /version, Methods: GET\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO 10-03 07:55:56 [launcher.py:44] Route: /v1/responses, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO 10-03 07:55:56 [launcher.py:44] Route: /v1/responses/{response_id}, Methods: GET\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO 10-03 07:55:56 [launcher.py:44] Route: /v1/responses/{response_id}/cancel, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO 10-03 07:55:56 [launcher.py:44] Route: /v1/chat/completions, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO 10-03 07:55:56 [launcher.py:44] Route: /v1/completions, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO 10-03 07:55:56 [launcher.py:44] R\n",
            "STDERR: \u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO:     Started server process [804]\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO:     Waiting for application startup.\n",
            "\u001b[1;36m(APIServer pid=804)\u001b[0;0m INFO:     Application startup complete.\n",
            "\n",
            "✓ VLLM server is up and running!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Jalankan dan fungsi tambahan"
      ],
      "metadata": {
        "id": "1Jee8Fp_8XaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from fastapi.responses import StreamingResponse\n",
        "import requests\n",
        "\n",
        "# mengirimkan Request skema untuk input\n",
        "class QuestionRequest(BaseModel):\n",
        "    question: str\n",
        "\n",
        "\n",
        "def ask_model(question: str):\n",
        "    \"\"\"\n",
        "    Kirimkan request ke model dan dapatkan respon.\n",
        "    \"\"\"\n",
        "    url = \"http://localhost:8000/v1/chat/completions\"  # Atur kembali jika kamu mendapati URL yang berbeda\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "    data = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": question\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, headers=headers, json=data)\n",
        "    response.raise_for_status()  # Kirimkan informasi jika ada error HTTP\n",
        "    return response.json()"
      ],
      "metadata": {
        "id": "9PFT_Gee8qro"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Coba gunakan modelnya\n",
        "\n"
      ],
      "metadata": {
        "id": "-OppOsps9mlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"\n",
        "the first president of america?\n",
        "\"\"\"\n",
        "\n",
        "# Umpamakan ask_model berasal dari cell Wt2lqQ_vfrdn tersedia\n",
        "try:\n",
        "    result = ask_model(question)\n",
        "    import json\n",
        "    print(json.dumps(result, indent=2))\n",
        "    abc = result['choices'][0]['message']['content']\n",
        "    print(abc)\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error sending request: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJXDqV0p9wfy",
        "outputId": "bac236c6-4eb1-4bb2-f4dc-31253ec54299"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-0173672a9aa64e4bb3314dee93b2e3fc\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1759478183,\n",
            "  \"model\": \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"Okay, so I need to figure out who the first president of America was. I remember hearing that it was George Washington, but I'm not entirely sure. Let me think through this step by step.\\n\\nFirst, George Washington was born on February 22, 1732, in Virginia. He was the second president of the United States, so the first one must have been someone before him. I think it was John Adams, but I'm not 100% certain. Maybe I should look into the historical timeline.\\n\\nIn the 1700s, there was a time when the U.S. was a colony of England, and the first president would have been someone from England. That would make sense because England was a neighboring country at that time. So, maybe John Adams was the first president. He was a statesman and played a significant role in setting up the country, so that makes sense.\\n\\nI also recall that George Washington was the first president of the United States since 1789, which means he was the first American president. Before him, there was no president, so he was indeed the first. It's interesting that he was the first since 1789, which is a bit of a recent jump, but that's because of the changes in the U.S. history that happened around that time.\\n\\nI should also consider the other presidents. The first president of the U.S. was elected by the 13th state, which was Delaware. The 13th state was created in 1787, so the first president would have been elected before that, which would be John Adams. That fits with the timeline I'm thinking of.\\n\\nAdditionally, George Washington was the first president of the United States since 1789, so he was the first American president. He was also the first president of the United States since 1789, which is a bit of a recent jump. But that's because of the changes in the U.S. history that happened around that time.\\n\\nI think I've covered the main points. George Washington was the first president of the United States, and he was the first since 1789, making him the first American president as well. John Adams was the first president of the U.S. since Delaware was created in 1787, which also makes him the first since 1787. So, both John Adams and George Washington were the first presidents, but George Washington was the first since 1789, which is a bit more recent.\\n\\nI don't think I've missed anything here. It all ties back to the timeline and the order in which these presidents were elected. So, George Washington was the first since 1789, and John Adams was the first since Delaware was created in 1787. Therefore, George Washington is the first American president because he was the first since 1789, which is a bit more recent than the first since 1787.\\n</think>\\n\\nThe first president of the United States was George Washington, who was elected on February 22, 1789, making him the first since 1789. Before him, the first president was John Adams, who was elected on February 5, 1787, making him the first since Delaware was created that year. Therefore, George Washington was the first American president because he was the first since 1789.\",\n",
            "        \"refusal\": null,\n",
            "        \"annotations\": null,\n",
            "        \"audio\": null,\n",
            "        \"function_call\": null,\n",
            "        \"tool_calls\": [],\n",
            "        \"reasoning_content\": null\n",
            "      },\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"stop_reason\": null,\n",
            "      \"token_ids\": null\n",
            "    }\n",
            "  ],\n",
            "  \"service_tier\": null,\n",
            "  \"system_fingerprint\": null,\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 12,\n",
            "    \"total_tokens\": 734,\n",
            "    \"completion_tokens\": 722,\n",
            "    \"prompt_tokens_details\": null\n",
            "  },\n",
            "  \"prompt_logprobs\": null,\n",
            "  \"prompt_token_ids\": null,\n",
            "  \"kv_transfer_params\": null\n",
            "}\n",
            "Okay, so I need to figure out who the first president of America was. I remember hearing that it was George Washington, but I'm not entirely sure. Let me think through this step by step.\n",
            "\n",
            "First, George Washington was born on February 22, 1732, in Virginia. He was the second president of the United States, so the first one must have been someone before him. I think it was John Adams, but I'm not 100% certain. Maybe I should look into the historical timeline.\n",
            "\n",
            "In the 1700s, there was a time when the U.S. was a colony of England, and the first president would have been someone from England. That would make sense because England was a neighboring country at that time. So, maybe John Adams was the first president. He was a statesman and played a significant role in setting up the country, so that makes sense.\n",
            "\n",
            "I also recall that George Washington was the first president of the United States since 1789, which means he was the first American president. Before him, there was no president, so he was indeed the first. It's interesting that he was the first since 1789, which is a bit of a recent jump, but that's because of the changes in the U.S. history that happened around that time.\n",
            "\n",
            "I should also consider the other presidents. The first president of the U.S. was elected by the 13th state, which was Delaware. The 13th state was created in 1787, so the first president would have been elected before that, which would be John Adams. That fits with the timeline I'm thinking of.\n",
            "\n",
            "Additionally, George Washington was the first president of the United States since 1789, so he was the first American president. He was also the first president of the United States since 1789, which is a bit of a recent jump. But that's because of the changes in the U.S. history that happened around that time.\n",
            "\n",
            "I think I've covered the main points. George Washington was the first president of the United States, and he was the first since 1789, making him the first American president as well. John Adams was the first president of the U.S. since Delaware was created in 1787, which also makes him the first since 1787. So, both John Adams and George Washington were the first presidents, but George Washington was the first since 1789, which is a bit more recent.\n",
            "\n",
            "I don't think I've missed anything here. It all ties back to the timeline and the order in which these presidents were elected. So, George Washington was the first since 1789, and John Adams was the first since Delaware was created in 1787. Therefore, George Washington is the first American president because he was the first since 1789, which is a bit more recent than the first since 1787.\n",
            "</think>\n",
            "\n",
            "The first president of the United States was George Washington, who was elected on February 22, 1789, making him the first since 1789. Before him, the first president was John Adams, who was elected on February 5, 1787, making him the first since Delaware was created that year. Therefore, George Washington was the first American president because he was the first since 1789.\n"
          ]
        }
      ]
    }
  ]
}